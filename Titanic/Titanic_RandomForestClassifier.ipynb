{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step, logistic Regression.\n",
    "\n",
    "I've been trying several different methods out for working with this Titanic data.  Many are inspired by others' work. I'm using this dataset as a way to formalize some knowledge of these methodologies I learned for my thesis (though often called differently) and learning the ins and outs of how to use them with sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, I want to get into the habit of making nicely contained functions that do the work on the raw input and processesing it. This should clean up the code and make tweaks easier (and swapping algs easier as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanup_data(data):\n",
    "    \"\"\"Return a cleaned up raw dataset.\"\"\"\n",
    "    \n",
    "    # There are missing AGES in the input data. We need to figure out how to deal with them.\n",
    "    # For now, I'm replacing them with a very negative number as the fact we don't know the \n",
    "    # age for these people may be interesting\n",
    "    data['Age'].fillna(-100, inplace=True)\n",
    "    \n",
    "    # Sex is a M/F only entry. Let's code this as 0/1\n",
    "    data.loc[data[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    data.loc[data[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "    # Similarly, there are exactly three entries for Embarked Q, C, S, and missing. \n",
    "    data[\"Embarked\"].fillna(\"Missing\", inplace=True)\n",
    "    data.loc[data[\"Embarked\"] == \"Missing\", \"Embarked\"] = 0\n",
    "    data.loc[data[\"Embarked\"] == \"Q\", \"Embarked\"] = 1\n",
    "    data.loc[data[\"Embarked\"] == \"C\", \"Embarked\"] = 2\n",
    "    data.loc[data[\"Embarked\"] == \"S\", \"Embarked\"] = 3\n",
    "    \n",
    "    # Some of the test data is missing a Fare\n",
    "    data[\"Fare\"].fillna(data[\"Fare\"].median(), inplace=True)\n",
    "    \n",
    "    #return the modified dataset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're at it, let's make a tool to quickly create my submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_submission(alg, train, test, predictors, filename):\n",
    "    \"\"\"Create Kaggle Output formatted CSV file.\n",
    "    \n",
    "    Input : alg -- object for the model\n",
    "            train -- training set\n",
    "            test -- testing set\n",
    "            predictors -- columns used when fitting\n",
    "            filename -- output file name\n",
    "    \"\"\"\n",
    "    alg.fit(train[predictors], train[\"Survived\"])\n",
    "    predictions = alg.predict(test[predictors])\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "            \"PassengerId\" : test[\"PassengerId\"],\n",
    "            \"Survived\" : predictions\n",
    "        })\n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Let's start the main loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", dtype={\"Age\":np.float64},)\n",
    "test = pd.read_csv(\"data/test.csv\", dtype={\"Age\":np.float64},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run out cleanup script\n",
    "train_data = cleanup_data(train)\n",
    "test_data = cleanup_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819304152637\n"
     ]
    }
   ],
   "source": [
    "# Let's run a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# List of the data we want to use\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    random_state=69,\n",
    "    n_estimators=100, \n",
    "    min_samples_split=4, \n",
    "    min_samples_leaf=2)\n",
    "\n",
    "scores = cross_validation.cross_val_score(\n",
    "    model, \n",
    "    train_data[predictors], \n",
    "    train_data[\"Survived\"], \n",
    "    cv=3)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's take a look at some subsplits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[predictors], \n",
    "                                                    train_data[\"Survived\"] ,\n",
    "                                                    test_size=0.25, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassified Samples 41 of 223\n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Let's fit it with our model:\n",
    "# Run on our subsample\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Run predictions on our fake subsample\n",
    "y_pred = model.predict(X_test)\n",
    "no_samples = len(y_test)\n",
    "print(\"Missclassified Samples %d of %d\" %\n",
    "      ((y_test != y_pred).sum(), no_samples))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
