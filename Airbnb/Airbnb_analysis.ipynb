{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed walk through the Airbnb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Setup out of the way\n",
    "\n",
    "* Setup matplotlib for inline plotting\n",
    "* Setup math-related, statistics, machine learning, DataFrames\n",
    "* airbnb_tools is a set up wrappers  to do some basic jobs written by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup plot environment\n",
    "%matplotlib inline\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from airbnb_tools import *\n",
    "import math\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data and start some Cleaning\n",
    "\n",
    "* Read in with pandas\n",
    "* At first, I was limiting to those with bookings. Turns out that's the wrong way to do it, they want a non-booking to be included\n",
    "* Replace missing data with -1 (this is for quick analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the training data\n",
    "train = pd.read_csv(\"data/train_users_2.csv\")\n",
    "test = pd.read_csv(\"data/test_users.csv\")\n",
    "\n",
    "# Join test and train so they get treated the same during cleaning.\n",
    "# We'll separate them for model testing.\n",
    "piv_train = train.shape[0]\n",
    "\n",
    "# We're going to drop the ID from the test data eventually. Need to make \n",
    "# sure we keep track of it\n",
    "testId = test['id']\n",
    "test[\"dataset\"] = \"test\"\n",
    "train[\"dataset\"] = \"train\"\n",
    "alldata = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "\n",
    "# Start some preliminary cleaning of the data.\n",
    "# Fill in missing data with -1 for now\n",
    "alldata.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function that takes two YYYY-MM-DD dates and calculates the difference between them.\n",
    "\n",
    "Note that we allow an optional keyword (noNeg) to force the minimum output to be 0. We do this because some of the inputs we're dealing with should always be > 0 and a negative is probably fubar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create some features from others that may be telling\n",
    "def days_between(d1, d2, noNeg=False):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
    "    outval = (d2-d1).days\n",
    "    if (outval > 0 or noNeg == False):\n",
    "        return outval\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Where were no bookings made?\n",
    "d1 = alldata[\"date_account_created\"].values\n",
    "d2 = alldata[\"date_first_booking\"].values\n",
    "elapsed = []\n",
    "for ii in range(0, len(alldata)):\n",
    "    if (d2[ii] != -1):\n",
    "        elapsed.append(days_between(d1[ii],d2[ii], noNeg=True))\n",
    "    else:\n",
    "        elapsed.append(10000.)\n",
    "# Add this to the DataFrame\n",
    "alldata[\"elapsed_booking_time\"] = elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another little function to convert the (numeric) time stamp keyword to useful values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What does the timestamp_first_active say?\n",
    "def tfa(x):\n",
    "    \"\"\" Return YYYY-MM-DD format for timestamp formatted data.\"\"\"\n",
    "    output = []\n",
    "    x = str(x)\n",
    "    return str(x[:4]) + '-' + str(x[4:6]) + '-' + str(x[6:8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the initial Time Stamp into useful bits. The creation delay is the time between\n",
    "# Their first search (which could be first) to when they created their account.\n",
    "tfa_year = []\n",
    "tfa_month = []\n",
    "tfa_day = []\n",
    "creation_delay = []\n",
    "tfa_vector = alldata[\"timestamp_first_active\"].values\n",
    "for ii in range(0, len(alldata)):\n",
    "    tfa_out = tfa(tfa_vector[ii])\n",
    "    creation_delay.append(days_between(tfa_out, d1[ii]))\n",
    "    \n",
    "    \n",
    "alldata[\"creation_delay\"] = creation_delay\n",
    "alldata.drop([\"timestamp_first_active\", \"date_account_created\", \n",
    "            \"date_first_booking\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up out of whack age data and remove unneeded features\n",
    "\n",
    "* For now, limit age to 15 < age < 100. Set others to -1\n",
    "* Remove ID which isn't a tracer of anything in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up Age a bit.  Assume anything with age < 18 and age > 100 are fubar and set to -1\n",
    "alldata['age'][(alldata['age'] < 15) | (alldata['age'] > 100)] = -1\n",
    "\n",
    "# ID is likely not super informative, so let's drop it\n",
    "alldata.drop(['id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and split the categorical values you want to use in a fit.\n",
    "\n",
    "* for now, I'm fitting nearly everything that's left.\n",
    "* Note that gender has M/F/prefer not to answer/Unknown, so not truely degenerate \n",
    "* Some of these may end up going later, but for now, let's see what we can do with ever feature.\n",
    "* This likely *will* overfit the data\n",
    "\n",
    "## Finally, pop the destination to y\n",
    "\n",
    "* Rather than the string labels for countries, let's go a value between 0 and max_coutnries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What Categorical Variables are we interested in?\n",
    "categorical_variables = ['gender', 'language', 'signup_method',  'signup_flow', \n",
    "                         'affiliate_channel', 'affiliate_provider', \n",
    "                         'first_affiliate_tracked', 'signup_app', \n",
    "                         'first_device_type', 'first_browser']\n",
    "alldataSplit = split_categorical_variables(alldata, categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, resplit the data and test set\n",
    "X = alldataSplit[alldataSplit[\"dataset\"]==\"train\"]\n",
    "X_test = alldataSplit[alldataSplit[\"dataset\"]==\"test\"]\n",
    "y = X.pop(\"country_destination\")\n",
    "\n",
    "X.drop([\"dataset\"], axis=1, inplace=True)\n",
    "X_test.drop([\"dataset\", \"country_destination\"], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "vals = le.fit_transform(y.values)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(range(np.amax(vals)+1))\n",
    "T = lb.transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a gradiant boost classifier\n",
    "\n",
    "* This wasn't behaving like I wanted. Namely, I need to read up on scoring a method like this, as I wasn't able to quickly \n",
    "    * see what features were important\n",
    "    * get quantitative measurements of how each paramter was affecting us, which meant we didn't get an idea of how to tune the model.\n",
    "* Need to read up on this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xgb_model = XGBClassifier(max_depth=3, n_estimators=10, learning_rate=0.1)\n",
    "#xgb_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a random forest classifier and see how that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_model = OneVsRestClassifier(RandomForestClassifier(\n",
    "                                n_estimators = 100, oob_score=True, n_jobs=-1, \n",
    "                                max_features_options=\"sqrt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7, 10, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr = dict()\n",
    "trp = dict()\n",
    "roc_auc = dict()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
